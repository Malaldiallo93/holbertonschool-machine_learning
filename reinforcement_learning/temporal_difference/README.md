Temporal Difference

Resources
Read or watch:

RL Course by David Silver - Lecture 4: Model-Free Prediction
RL Course by David Silver - Lecture 5: Model Free Control
Temporal Difference Learning (including Q-Learning)
Temporal-Difference Learning
Intro to reinforcement learning: temporal difference learning, SARSA vs. Q-learning
Temporal difference reinforcement learning
Reinforcement Learning: Temporal Difference (TD) Learning
On-Policy TD Control
Definitions to skim:

Monte Carlo method
Temporal difference learning
State–action–reward–state–action
Learning Objectives
What is Monte Carlo?
What is Temporal Difference?
What is bootstrapping?
What is n-step temporal difference?
What is TD(λ)?
What is an eligibility trace?
What is SARSA? SARSA(λ)? SARSAMAX?
What is ‘on-policy’ vs ‘off-policy’?
Requirements
General
Allowed editors: vi, vim, emacs
All your files will be interpreted/compiled on Ubuntu 20.04 LTS using python3 (version 3.9)
Your files will be executed with numpy (version 1.25.2), and gymnasium (version 0.29.1)
All your files should end with a new line
The first line of all your files should be exactly #!/usr/bin/env python3
A README.md file, at the root of the folder of the project, is mandatory
Your code should use the pycodestyle style (version 2.11.1)
All your modules should have documentation (python3 -c 'print(__import__("my_module").__doc__)')
All your classes should have documentation (python3 -c 'print(__import__("my_module").MyClass.__doc__)')
All your functions (inside and outside a class) should have documentation (python3 -c 'print(__import__("my_module").my_function.__doc__)' and python3 -c 'print(__import__("my_module").MyClass.my_function.__doc__)')
All your files must be executable
Your code should use the minimum number of operations